{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the performance of 8 Regressers across 8 Regression datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 21:47:09.645633: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-03 21:47:09.645659: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import sklearn.gaussian_process as gp\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1: Wine Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4      5.0  \n",
       "1         9.8      5.0  \n",
       "2         9.8      5.0  \n",
       "3         9.8      6.0  \n",
       "4         9.4      5.0  \n",
       "...       ...      ...  \n",
       "1594     10.5      5.0  \n",
       "1595     11.2      6.0  \n",
       "1596     11.0      6.0  \n",
       "1597     10.2      5.0  \n",
       "1598     11.0      6.0  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing data\n",
    "wine_df=pd.read_csv('datasets/winequality-red.csv', sep=';', dtype=float)\n",
    "wine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.700\n",
       "1       0.880\n",
       "2       0.760\n",
       "3       0.280\n",
       "4       0.700\n",
       "        ...  \n",
       "1594    0.600\n",
       "1595    0.550\n",
       "1596    0.510\n",
       "1597    0.645\n",
       "1598    0.310\n",
       "Name: volatile acidity, Length: 1599, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df['volatile acidity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  \n",
       "0         9.4  \n",
       "1         9.8  \n",
       "2         9.8  \n",
       "3         9.8  \n",
       "4         9.4  \n",
       "...       ...  \n",
       "1594     10.5  \n",
       "1595     11.2  \n",
       "1596     11.0  \n",
       "1597     10.2  \n",
       "1598     11.0  \n",
       "\n",
       "[1599 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=wine_df.drop('quality', axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5.0\n",
       "1       5.0\n",
       "2       5.0\n",
       "3       6.0\n",
       "4       5.0\n",
       "       ... \n",
       "1594    5.0\n",
       "1595    6.0\n",
       "1596    6.0\n",
       "1597    5.0\n",
       "1598    6.0\n",
       "Name: quality, Length: 1599, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=wine_df['quality']\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.iloc[1]+Y.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create linear regression object\n",
    "l_reg_wine = linear_model.LinearRegression()\n",
    " \n",
    "# train the model using the training sets\n",
    "l_reg_wine.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=100, gamma=0.1, max_iter=10000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf_wine = SVR(kernel=\"rbf\", C=100,max_iter=10000, gamma=0.1, epsilon=0.1)\n",
    "svr_rbf_wine.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=100, random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_regr_wine = DecisionTreeRegressor(max_depth=100, random_state=0)\n",
    "dr_regr_wine.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_f_wine= RandomForestRegressor(random_state=0)\n",
    "r_f_wine.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_wine = KNeighborsRegressor(n_neighbors=8)\n",
    "# n_neighbors=8\n",
    "\n",
    "kn_wine.fit(x_train,y_train)\n",
    "# print('Variance score: {}'.format(kn.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_wine = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "ada_wine.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=0.1, n_restarts_optimizer=10, normalize_y=True,\n",
       "                         random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr_wine = gp.GaussianProcessRegressor(n_restarts_optimizer=10, alpha=0.1, normalize_y=True, random_state=0)\n",
    "gpr_wine.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 21:47:11.751902: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-12-03 21:47:11.758268: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a-VirtualBox): /proc/driver/nvidia/version does not exist\n",
      "2021-12-03 21:47:11.758939: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               1536      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166,401\n",
      "Trainable params: 166,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "32/32 [==============================] - 1s 6ms/step - loss: 1.5897 - mean_absolute_error: 1.5897 - val_loss: 0.6327 - val_mean_absolute_error: 0.6327\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6479 - mean_absolute_error: 0.6479 - val_loss: 0.7348 - val_mean_absolute_error: 0.7348\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6320 - mean_absolute_error: 0.6320 - val_loss: 0.5707 - val_mean_absolute_error: 0.5707\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6113 - mean_absolute_error: 0.6113 - val_loss: 0.5268 - val_mean_absolute_error: 0.5268\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5978 - mean_absolute_error: 0.5978 - val_loss: 0.5735 - val_mean_absolute_error: 0.5735\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5763 - mean_absolute_error: 0.5763 - val_loss: 0.5170 - val_mean_absolute_error: 0.5170\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5776 - mean_absolute_error: 0.5776 - val_loss: 0.5272 - val_mean_absolute_error: 0.5272\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5751 - mean_absolute_error: 0.5751 - val_loss: 0.7010 - val_mean_absolute_error: 0.7010\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5827 - mean_absolute_error: 0.5827 - val_loss: 0.5239 - val_mean_absolute_error: 0.5239\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5825 - mean_absolute_error: 0.5825 - val_loss: 0.5759 - val_mean_absolute_error: 0.5759\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5709 - mean_absolute_error: 0.5709 - val_loss: 0.5103 - val_mean_absolute_error: 0.5103\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5479 - mean_absolute_error: 0.5479 - val_loss: 0.6100 - val_mean_absolute_error: 0.6100\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6337 - mean_absolute_error: 0.6337 - val_loss: 0.5117 - val_mean_absolute_error: 0.5117\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5456 - mean_absolute_error: 0.5456 - val_loss: 0.5307 - val_mean_absolute_error: 0.5307\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5490 - mean_absolute_error: 0.5490 - val_loss: 0.5057 - val_mean_absolute_error: 0.5057\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5639 - mean_absolute_error: 0.5639 - val_loss: 0.5150 - val_mean_absolute_error: 0.5150\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5463 - mean_absolute_error: 0.5463 - val_loss: 0.5115 - val_mean_absolute_error: 0.5115\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5266 - mean_absolute_error: 0.5266 - val_loss: 0.4968 - val_mean_absolute_error: 0.4968\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5407 - mean_absolute_error: 0.5407 - val_loss: 0.6016 - val_mean_absolute_error: 0.6016\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5490 - mean_absolute_error: 0.5490 - val_loss: 0.4953 - val_mean_absolute_error: 0.4953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f53244f37c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = x_train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()\n",
    "NN_model.fit(x_train, y_train, epochs=20, batch_size=32, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.42121059590691284\n",
      "R2: 0.3961138409936733\n",
      "Variance score: 0.3961138409936733\n"
     ]
    }
   ],
   "source": [
    "output = l_reg_wine.predict(x_test)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test, output)))\n",
    "print(f'R2: {r2_score(y_test, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6955914533139539\n",
      "R2: 0.002736267650245261\n"
     ]
    }
   ],
   "source": [
    "output = svr_rbf_wine.predict(x_test)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test, output)))\n",
    "print(f'R2: {r2_score(y_test, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.615625\n",
      "R2: 0.11738351254480284\n"
     ]
    }
   ],
   "source": [
    "output = dr_regr_wine.predict(x_test)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test, output)))\n",
    "print(f'R2: {r2_score(y_test, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.33578656250000005\n",
      "R2: 0.5185855734767024\n"
     ]
    }
   ],
   "source": [
    "output = r_f_wine.predict(x_test)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test, output)))\n",
    "print(f'R2: {r2_score(y_test, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.586328125\n",
      "R2: 0.15938620071684584\n"
     ]
    }
   ],
   "source": [
    "output = kn_wine.predict(x_test)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test, output)))\n",
    "print(f'R2: {r2_score(y_test, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.41209450611196896\n",
      "R2: 0.4091835037821233\n"
     ]
    }
   ],
   "source": [
    "output = ada_wine.predict(x_test)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test, output)))\n",
    "print(f'R2: {r2_score(y_test, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5366046185012779\n",
      "R2: 0.23067438207702085\n"
     ]
    }
   ],
   "source": [
    "output = gpr_wine.predict(x_test)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test, output)))\n",
    "print(f'R2: {r2_score(y_test, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.48453284412239983\n",
      "R2: 0.3053292557384949\n"
     ]
    }
   ],
   "source": [
    "output = NN_model.predict(x_test)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test, output)))\n",
    "print(f'R2: {r2_score(y_test, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2: Communities and Crime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list()\n",
    "with open(\"datasets/communities.names\",\"r\") as f:\n",
    "    for l in f.readlines():\n",
    "        l = l.split(\" \")\n",
    "        if l[0] == \"@attribute\":\n",
    "            names.append(l[1])\n",
    "comm_dataset = pd.read_csv(\"datasets/communities.data\", delimiter=',', names=names)\n",
    "\n",
    "# feature selection\n",
    "L_drop = [comm_dataset.columns[0], comm_dataset.columns[1], comm_dataset.columns[2], comm_dataset.columns[3]]\n",
    "for i in range(11,len(comm_dataset.columns)):\n",
    "    L_drop.append(comm_dataset.columns[i])\n",
    "comm_df = comm_dataset.drop(columns=L_drop)\n",
    "\n",
    "comm_df['y'] = comm_dataset['state']\n",
    "comm_df = comm_df.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "0   1.0        0.19           0.33          0.02          0.90          0.12   \n",
       "1   1.0        0.00           0.16          0.12          0.74          0.45   \n",
       "2   1.0        0.00           0.42          0.49          0.56          0.17   \n",
       "3   1.0        0.04           0.77          1.00          0.08          0.12   \n",
       "4   1.0        0.01           0.55          0.02          0.95          0.09   \n",
       "\n",
       "   racePctHisp     y  \n",
       "0         0.17   8.0  \n",
       "1         0.07  53.0  \n",
       "2         0.04  24.0  \n",
       "3         0.10  34.0  \n",
       "4         0.05  42.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0=comm_df.drop('y', axis=1)\n",
    "Y0=comm_df['y']\n",
    "\n",
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "x_train0, x_test0, y_train0, y_test0 = train_test_split(X0,Y0, train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create linear regression object\n",
    "l_reg_comm_df = linear_model.LinearRegression()\n",
    " \n",
    "# train the model using the training sets\n",
    "l_reg_comm_df.fit(x_train0, y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, gamma=0.1, max_iter=10000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf_comm_df  = SVR(kernel=\"rbf\", C=100,max_iter=10000, gamma=0.1, epsilon=0.1)\n",
    "svr_rbf_comm_df.fit(x_train0, y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=100, random_state=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_regr_comm_df  = DecisionTreeRegressor(max_depth=100, random_state=0)\n",
    "dr_regr_comm_df.fit(x_train0, y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_f_comm_df= RandomForestRegressor(random_state=0)\n",
    "r_f_comm_df.fit(x_train0, y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_comm_df = KNeighborsRegressor(n_neighbors=8)\n",
    "kn_comm_df.fit(x_train0,y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_comm_df  = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "ada_comm_df .fit(x_train0,y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=0.1, n_restarts_optimizer=10, normalize_y=True,\n",
       "                         random_state=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr_comm_df  = gp.GaussianProcessRegressor(n_restarts_optimizer=10, alpha=0.1, normalize_y=True, random_state=0)\n",
    "gpr_comm_df.fit(x_train0, y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 128)               1024      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 165,889\n",
      "Trainable params: 165,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 21.5538 - mean_absolute_error: 21.5538 - val_loss: 16.5593 - val_mean_absolute_error: 16.5593\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 15.1156 - mean_absolute_error: 15.1156 - val_loss: 15.2417 - val_mean_absolute_error: 15.2417\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 13.9573 - mean_absolute_error: 13.9573 - val_loss: 14.1459 - val_mean_absolute_error: 14.1459\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 13.8761 - mean_absolute_error: 13.8761 - val_loss: 13.3485 - val_mean_absolute_error: 13.3485\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 13.3494 - mean_absolute_error: 13.3494 - val_loss: 13.0886 - val_mean_absolute_error: 13.0886\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 13.2529 - mean_absolute_error: 13.2529 - val_loss: 13.2023 - val_mean_absolute_error: 13.2023\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 13.0541 - mean_absolute_error: 13.0541 - val_loss: 13.0524 - val_mean_absolute_error: 13.0524\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 13.0564 - mean_absolute_error: 13.0564 - val_loss: 13.9212 - val_mean_absolute_error: 13.9212\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 13.1541 - mean_absolute_error: 13.1541 - val_loss: 13.1540 - val_mean_absolute_error: 13.1540\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 13.2419 - mean_absolute_error: 13.2419 - val_loss: 13.0064 - val_mean_absolute_error: 13.0064\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 13.0150 - mean_absolute_error: 13.0150 - val_loss: 12.7101 - val_mean_absolute_error: 12.7101\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 12.9574 - mean_absolute_error: 12.9574 - val_loss: 13.2691 - val_mean_absolute_error: 13.2691\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 12.9535 - mean_absolute_error: 12.9535 - val_loss: 12.9748 - val_mean_absolute_error: 12.9748\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 13.1394 - mean_absolute_error: 13.1394 - val_loss: 12.6518 - val_mean_absolute_error: 12.6518\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 13.0272 - mean_absolute_error: 13.0272 - val_loss: 12.8653 - val_mean_absolute_error: 12.8653\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 13.1973 - mean_absolute_error: 13.1973 - val_loss: 12.7192 - val_mean_absolute_error: 12.7192\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 13.0094 - mean_absolute_error: 13.0094 - val_loss: 12.9701 - val_mean_absolute_error: 12.9701\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 13.3076 - mean_absolute_error: 13.3076 - val_loss: 14.8293 - val_mean_absolute_error: 14.8293\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 13.4527 - mean_absolute_error: 13.4527 - val_loss: 13.4501 - val_mean_absolute_error: 13.4501\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 12.6993 - mean_absolute_error: 12.6993 - val_loss: 12.8352 - val_mean_absolute_error: 12.8352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f531a777fd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model0 = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model0.add(Dense(128, kernel_initializer='normal',input_dim = x_train0.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model0.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model0.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model0.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model0.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model0.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model0.summary()\n",
    "NN_model0.fit(x_train0, y_train0, epochs=20, batch_size=32, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 229.62157333270042\n",
      "R2: 0.17122120150807074\n"
     ]
    }
   ],
   "source": [
    "output = l_reg_comm_df.predict(x_test0)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test0, output)))\n",
    "print(f'R2: {r2_score(y_test0, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 260.2299488141496\n",
      "R2: 0.060745638227481136\n"
     ]
    }
   ],
   "source": [
    "output = svr_rbf_comm_df.predict(x_test0)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test0, output)))\n",
    "print(f'R2: {r2_score(y_test0, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 399.453634085213\n",
      "R2: -0.4417578370596049\n"
     ]
    }
   ],
   "source": [
    "output = dr_regr_comm_df.predict(x_test0)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test0, output)))\n",
    "print(f'R2: {r2_score(y_test0, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 198.896084962406\n",
      "R2: 0.2821194632219841\n"
     ]
    }
   ],
   "source": [
    "output = r_f_comm_df.predict(x_test0)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test0, output)))\n",
    "print(f'R2: {r2_score(y_test0, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 261.3307095864662\n",
      "R2: 0.05677263526845289\n"
     ]
    }
   ],
   "source": [
    "output = kn_comm_df.predict(x_test0)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test0, output)))\n",
    "print(f'R2: {r2_score(y_test0, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 226.34451945871913\n",
      "R2: 0.18304915274476208\n"
     ]
    }
   ],
   "source": [
    "output = ada_comm_df.predict(x_test0)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test0, output)))\n",
    "print(f'R2: {r2_score(y_test0, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 241.9871467405199\n",
      "R2: 0.1265898329356261\n"
     ]
    }
   ],
   "source": [
    "output = gpr_comm_df.predict(x_test0)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test0, output)))\n",
    "print(f'R2: {r2_score(y_test0, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 255.68043497045974\n",
      "R2: 0.07716631056401513\n"
     ]
    }
   ],
   "source": [
    "output = NN_model0.predict(x_test0)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test0, output)))\n",
    "print(f'R2: {r2_score(y_test0, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 3: QSAR aquatic toxicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPSA</th>\n",
       "      <th>SAacc</th>\n",
       "      <th>H-050</th>\n",
       "      <th>MLOGP</th>\n",
       "      <th>RDCHI</th>\n",
       "      <th>GATS1p</th>\n",
       "      <th>nN</th>\n",
       "      <th>C-040</th>\n",
       "      <th>LC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.419</td>\n",
       "      <td>1.225</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.638</td>\n",
       "      <td>1.401</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.23</td>\n",
       "      <td>11.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.799</td>\n",
       "      <td>2.930</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.23</td>\n",
       "      <td>11.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.453</td>\n",
       "      <td>2.887</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.23</td>\n",
       "      <td>11.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.068</td>\n",
       "      <td>2.758</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>24.06</td>\n",
       "      <td>35.776</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.326</td>\n",
       "      <td>2.837</td>\n",
       "      <td>0.849</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>9.23</td>\n",
       "      <td>11.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.275</td>\n",
       "      <td>2.727</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.165</td>\n",
       "      <td>3.111</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>13.14</td>\n",
       "      <td>9.507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.859</td>\n",
       "      <td>2.614</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.255</td>\n",
       "      <td>1.800</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TPSA   SAacc  H-050  MLOGP  RDCHI  GATS1p   nN  C-040   LC50\n",
       "0     0.00   0.000    0.0  2.419  1.225   0.667  0.0    0.0  3.740\n",
       "1     0.00   0.000    0.0  2.638  1.401   0.632  0.0    0.0  4.330\n",
       "2     9.23  11.000    0.0  5.799  2.930   0.486  0.0    0.0  7.019\n",
       "3     9.23  11.000    0.0  5.453  2.887   0.495  0.0    0.0  6.723\n",
       "4     9.23  11.000    0.0  4.068  2.758   0.695  0.0    0.0  5.979\n",
       "..     ...     ...    ...    ...    ...     ...  ...    ...    ...\n",
       "541  24.06  35.776    2.0  3.326  2.837   0.849  2.0    0.0  4.651\n",
       "542   9.23  11.000    0.0  3.275  2.727   0.874  0.0    0.0  3.953\n",
       "543   0.00   0.000    0.0  5.165  3.111   0.732  0.0    0.0  6.219\n",
       "544  13.14   9.507    0.0  2.859  2.614   0.827  0.0    0.0  4.995\n",
       "545   0.00   0.000    0.0  2.255  1.800   0.917  0.0    0.0  2.480\n",
       "\n",
       "[546 rows x 9 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#immporting data\n",
    "toxic_df=pd.read_csv('datasets/qsar_aquatic_toxicity.csv',  sep=';', \n",
    "                     names=[\"TPSA\",\"SAacc\", \"H-050\", \"MLOGP\", \"RDCHI\", \"GATS1p\", \"nN\", \"C-040\", \"LC50\"],\n",
    "                    dtype=float)\n",
    "toxic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=toxic_df.drop('LC50', axis=1)\n",
    "Y1=toxic_df['LC50']\n",
    "\n",
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(X1,Y1, train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create linear regression object\n",
    "l_reg_toxic = linear_model.LinearRegression()\n",
    " \n",
    "# train the model using the training sets\n",
    "l_reg_toxic.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, gamma=0.1, max_iter=10000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf_toxic  = SVR(kernel=\"rbf\", C=100,max_iter=10000, gamma=0.1, epsilon=0.1)\n",
    "svr_rbf_toxic.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=100, random_state=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_regr_toxic  = DecisionTreeRegressor(max_depth=100, random_state=0)\n",
    "dr_regr_toxic.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_f_toxic= RandomForestRegressor(random_state=0)\n",
    "r_f_toxic.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_toxic = KNeighborsRegressor(n_neighbors=8)\n",
    "kn_toxic.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_toxic  = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "ada_toxic .fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=0.1, n_restarts_optimizer=10, normalize_y=True,\n",
       "                         random_state=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr_toxic  = gp.GaussianProcessRegressor(n_restarts_optimizer=10, alpha=0.1, normalize_y=True, random_state=0)\n",
    "gpr_toxic.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 128)               1152      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166,017\n",
      "Trainable params: 166,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 3.1808 - mean_absolute_error: 3.1808 - val_loss: 2.6678 - val_mean_absolute_error: 2.6678\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2.6457 - mean_absolute_error: 2.6457 - val_loss: 2.4827 - val_mean_absolute_error: 2.4827\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.8223 - mean_absolute_error: 1.8223 - val_loss: 1.4173 - val_mean_absolute_error: 1.4173\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.2388 - mean_absolute_error: 1.2388 - val_loss: 1.3041 - val_mean_absolute_error: 1.3041\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1526 - mean_absolute_error: 1.1526 - val_loss: 1.2494 - val_mean_absolute_error: 1.2494\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0394 - mean_absolute_error: 1.0394 - val_loss: 1.1723 - val_mean_absolute_error: 1.1723\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0176 - mean_absolute_error: 1.0176 - val_loss: 0.9646 - val_mean_absolute_error: 0.9646\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9951 - mean_absolute_error: 0.9951 - val_loss: 1.0417 - val_mean_absolute_error: 1.0417\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0383 - mean_absolute_error: 1.0383 - val_loss: 1.3377 - val_mean_absolute_error: 1.3377\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0483 - mean_absolute_error: 1.0483 - val_loss: 1.2223 - val_mean_absolute_error: 1.2223\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0945 - mean_absolute_error: 1.0945 - val_loss: 1.0613 - val_mean_absolute_error: 1.0613\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9966 - mean_absolute_error: 0.9966 - val_loss: 1.0902 - val_mean_absolute_error: 1.0902\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9280 - mean_absolute_error: 0.9280 - val_loss: 0.9977 - val_mean_absolute_error: 0.9977\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9220 - mean_absolute_error: 0.9220 - val_loss: 0.9987 - val_mean_absolute_error: 0.9987\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9004 - mean_absolute_error: 0.9004 - val_loss: 1.0381 - val_mean_absolute_error: 1.0381\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8971 - mean_absolute_error: 0.8971 - val_loss: 1.0419 - val_mean_absolute_error: 1.0419\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9410 - mean_absolute_error: 0.9410 - val_loss: 1.0478 - val_mean_absolute_error: 1.0478\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0654 - mean_absolute_error: 1.0654 - val_loss: 1.1098 - val_mean_absolute_error: 1.1098\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9221 - mean_absolute_error: 0.9221 - val_loss: 1.1218 - val_mean_absolute_error: 1.1218\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9518 - mean_absolute_error: 0.9518 - val_loss: 1.0562 - val_mean_absolute_error: 1.0562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f531a651be0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model1 = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model1.add(Dense(128, kernel_initializer='normal',input_dim = x_train1.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model1.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model1.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model1.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model1.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model1.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model1.summary()\n",
    "NN_model1.fit(x_train1, y_train1, epochs=20, batch_size=32, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.3112337527395346\n",
      "R2: 0.47686209010414504\n"
     ]
    }
   ],
   "source": [
    "output = l_reg_toxic.predict(x_test1)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test1, output)))\n",
    "print(f'R2: {r2_score(y_test1, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.470616378696796\n",
      "R2: 0.4132738140680894\n"
     ]
    }
   ],
   "source": [
    "output = svr_rbf_toxic.predict(x_test1)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test1, output)))\n",
    "print(f'R2: {r2_score(y_test1, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.571019240404041\n",
      "R2: -0.025749702459170187\n"
     ]
    }
   ],
   "source": [
    "output = dr_regr_toxic.predict(x_test1)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test1, output)))\n",
    "print(f'R2: {r2_score(y_test1, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.2310705641129418\n",
      "R2: 0.508844490542729\n"
     ]
    }
   ],
   "source": [
    "output = r_f_toxic.predict(x_test1)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test1, output)))\n",
    "print(f'R2: {r2_score(y_test1, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.9884949348011363\n",
      "R2: 0.20665778938578083\n"
     ]
    }
   ],
   "source": [
    "output = kn_toxic.predict(x_test1)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test1, output)))\n",
    "print(f'R2: {r2_score(y_test1, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.4141891214669824\n",
      "R2: 0.43578638083712395\n"
     ]
    }
   ],
   "source": [
    "output = ada_toxic.predict(x_test1)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test1, output)))\n",
    "print(f'R2: {r2_score(y_test1, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.6441963204125267\n",
      "R2: 0.3440212893223742\n"
     ]
    }
   ],
   "source": [
    "output = gpr_toxic.predict(x_test1)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test1, output)))\n",
    "print(f'R2: {r2_score(y_test1, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.8329383308719465\n",
      "R2: 0.26871961206231976\n"
     ]
    }
   ],
   "source": [
    "output = NN_model1.predict(x_test1)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test1, output)))\n",
    "print(f'R2: {r2_score(y_test1, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 4: Facebook metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "fb_df = pd.read_csv('datasets/dataset_Facebook.csv', sep=';', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page total likes</th>\n",
       "      <th>Type_Link</th>\n",
       "      <th>Type_Photo</th>\n",
       "      <th>Type_Status</th>\n",
       "      <th>Type_Video</th>\n",
       "      <th>Category</th>\n",
       "      <th>Post Month</th>\n",
       "      <th>Post Weekday</th>\n",
       "      <th>Post Hour</th>\n",
       "      <th>Paid</th>\n",
       "      <th>...</th>\n",
       "      <th>Lifetime Engaged Users</th>\n",
       "      <th>Lifetime Post Consumers</th>\n",
       "      <th>Lifetime Post Consumptions</th>\n",
       "      <th>Lifetime Post Impressions by people who have liked your Page</th>\n",
       "      <th>Lifetime Post reach by people who like your Page</th>\n",
       "      <th>Lifetime People who have liked your Page and engaged with your post</th>\n",
       "      <th>comment</th>\n",
       "      <th>like</th>\n",
       "      <th>share</th>\n",
       "      <th>Total Interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>178</td>\n",
       "      <td>109</td>\n",
       "      <td>159</td>\n",
       "      <td>3078</td>\n",
       "      <td>1640</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1457</td>\n",
       "      <td>1361</td>\n",
       "      <td>1674</td>\n",
       "      <td>11710</td>\n",
       "      <td>6112</td>\n",
       "      <td>1108</td>\n",
       "      <td>5</td>\n",
       "      <td>130.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>177</td>\n",
       "      <td>113</td>\n",
       "      <td>154</td>\n",
       "      <td>2812</td>\n",
       "      <td>1503</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2211</td>\n",
       "      <td>790</td>\n",
       "      <td>1119</td>\n",
       "      <td>61027</td>\n",
       "      <td>32048</td>\n",
       "      <td>1386</td>\n",
       "      <td>58</td>\n",
       "      <td>1572.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>671</td>\n",
       "      <td>410</td>\n",
       "      <td>580</td>\n",
       "      <td>6228</td>\n",
       "      <td>3200</td>\n",
       "      <td>396</td>\n",
       "      <td>19</td>\n",
       "      <td>325.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>85093</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>733</td>\n",
       "      <td>708</td>\n",
       "      <td>985</td>\n",
       "      <td>4750</td>\n",
       "      <td>2876</td>\n",
       "      <td>392</td>\n",
       "      <td>5</td>\n",
       "      <td>53.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>81370</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>537</td>\n",
       "      <td>508</td>\n",
       "      <td>687</td>\n",
       "      <td>3961</td>\n",
       "      <td>2104</td>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>81370</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>625</td>\n",
       "      <td>572</td>\n",
       "      <td>795</td>\n",
       "      <td>4742</td>\n",
       "      <td>2388</td>\n",
       "      <td>363</td>\n",
       "      <td>4</td>\n",
       "      <td>93.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>81370</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>626</td>\n",
       "      <td>574</td>\n",
       "      <td>832</td>\n",
       "      <td>4534</td>\n",
       "      <td>2452</td>\n",
       "      <td>370</td>\n",
       "      <td>7</td>\n",
       "      <td>91.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>81370</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>564</td>\n",
       "      <td>524</td>\n",
       "      <td>743</td>\n",
       "      <td>3861</td>\n",
       "      <td>2200</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Page total likes  Type_Link  Type_Photo  Type_Status  Type_Video  \\\n",
       "0              139441          0           1            0           0   \n",
       "1              139441          0           0            1           0   \n",
       "2              139441          0           1            0           0   \n",
       "3              139441          0           1            0           0   \n",
       "4              139441          0           1            0           0   \n",
       "..                ...        ...         ...          ...         ...   \n",
       "495             85093          0           1            0           0   \n",
       "496             81370          0           1            0           0   \n",
       "497             81370          0           1            0           0   \n",
       "498             81370          0           1            0           0   \n",
       "499             81370          0           1            0           0   \n",
       "\n",
       "     Category  Post Month  Post Weekday  Post Hour  Paid  ...  \\\n",
       "0           2          12             4          3   0.0  ...   \n",
       "1           2          12             3         10   0.0  ...   \n",
       "2           3          12             3          3   0.0  ...   \n",
       "3           2          12             2         10   1.0  ...   \n",
       "4           2          12             2          3   0.0  ...   \n",
       "..        ...         ...           ...        ...   ...  ...   \n",
       "495         3           1             7          2   0.0  ...   \n",
       "496         2           1             5          8   0.0  ...   \n",
       "497         1           1             5          2   0.0  ...   \n",
       "498         3           1             4         11   0.0  ...   \n",
       "499         2           1             4          4   NaN  ...   \n",
       "\n",
       "     Lifetime Engaged Users  Lifetime Post Consumers  \\\n",
       "0                       178                      109   \n",
       "1                      1457                     1361   \n",
       "2                       177                      113   \n",
       "3                      2211                      790   \n",
       "4                       671                      410   \n",
       "..                      ...                      ...   \n",
       "495                     733                      708   \n",
       "496                     537                      508   \n",
       "497                     625                      572   \n",
       "498                     626                      574   \n",
       "499                     564                      524   \n",
       "\n",
       "     Lifetime Post Consumptions  \\\n",
       "0                           159   \n",
       "1                          1674   \n",
       "2                           154   \n",
       "3                          1119   \n",
       "4                           580   \n",
       "..                          ...   \n",
       "495                         985   \n",
       "496                         687   \n",
       "497                         795   \n",
       "498                         832   \n",
       "499                         743   \n",
       "\n",
       "     Lifetime Post Impressions by people who have liked your Page  \\\n",
       "0                                                 3078              \n",
       "1                                                11710              \n",
       "2                                                 2812              \n",
       "3                                                61027              \n",
       "4                                                 6228              \n",
       "..                                                 ...              \n",
       "495                                               4750              \n",
       "496                                               3961              \n",
       "497                                               4742              \n",
       "498                                               4534              \n",
       "499                                               3861              \n",
       "\n",
       "     Lifetime Post reach by people who like your Page  \\\n",
       "0                                                1640   \n",
       "1                                                6112   \n",
       "2                                                1503   \n",
       "3                                               32048   \n",
       "4                                                3200   \n",
       "..                                                ...   \n",
       "495                                              2876   \n",
       "496                                              2104   \n",
       "497                                              2388   \n",
       "498                                              2452   \n",
       "499                                              2200   \n",
       "\n",
       "     Lifetime People who have liked your Page and engaged with your post  \\\n",
       "0                                                  119                     \n",
       "1                                                 1108                     \n",
       "2                                                  132                     \n",
       "3                                                 1386                     \n",
       "4                                                  396                     \n",
       "..                                                 ...                     \n",
       "495                                                392                     \n",
       "496                                                301                     \n",
       "497                                                363                     \n",
       "498                                                370                     \n",
       "499                                                316                     \n",
       "\n",
       "     comment    like  share  Total Interactions  \n",
       "0          4    79.0   17.0                 100  \n",
       "1          5   130.0   29.0                 164  \n",
       "2          0    66.0   14.0                  80  \n",
       "3         58  1572.0  147.0                1777  \n",
       "4         19   325.0   49.0                 393  \n",
       "..       ...     ...    ...                 ...  \n",
       "495        5    53.0   26.0                  84  \n",
       "496        0    53.0   22.0                  75  \n",
       "497        4    93.0   18.0                 115  \n",
       "498        7    91.0   38.0                 136  \n",
       "499        0    91.0   28.0                 119  \n",
       "\n",
       "[500 rows x 22 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cat = [\"Type\"]\n",
    "\n",
    "# replace the columns with categorical values by its one hot encoding\n",
    "print(features_cat)\n",
    "for feat in features_cat:\n",
    "    tmp_df = pd.get_dummies(fb_df[feat], prefix=feat)\n",
    "    idx = fb_df.columns.get_loc(feat)\n",
    "    for i, col in enumerate(tmp_df.columns):\n",
    "        fb_df.insert(idx+i, col, tmp_df[col])\n",
    "    fb_df = fb_df.drop(feat, axis=1)\n",
    "\n",
    "fb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete every row containing at least one 'Nan'\n",
    "fb_df = fb_df.dropna(axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page total likes</th>\n",
       "      <th>Type_Link</th>\n",
       "      <th>Type_Photo</th>\n",
       "      <th>Type_Status</th>\n",
       "      <th>Type_Video</th>\n",
       "      <th>Category</th>\n",
       "      <th>Post Month</th>\n",
       "      <th>Post Weekday</th>\n",
       "      <th>Post Hour</th>\n",
       "      <th>Paid</th>\n",
       "      <th>...</th>\n",
       "      <th>Lifetime Post Total Impressions</th>\n",
       "      <th>Lifetime Engaged Users</th>\n",
       "      <th>Lifetime Post Consumers</th>\n",
       "      <th>Lifetime Post Consumptions</th>\n",
       "      <th>Lifetime Post Impressions by people who have liked your Page</th>\n",
       "      <th>Lifetime Post reach by people who like your Page</th>\n",
       "      <th>Lifetime People who have liked your Page and engaged with your post</th>\n",
       "      <th>comment</th>\n",
       "      <th>like</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5091</td>\n",
       "      <td>178</td>\n",
       "      <td>109</td>\n",
       "      <td>159</td>\n",
       "      <td>3078</td>\n",
       "      <td>1640</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>79</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19057</td>\n",
       "      <td>1457</td>\n",
       "      <td>1361</td>\n",
       "      <td>1674</td>\n",
       "      <td>11710</td>\n",
       "      <td>6112</td>\n",
       "      <td>1108</td>\n",
       "      <td>5</td>\n",
       "      <td>130</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4373</td>\n",
       "      <td>177</td>\n",
       "      <td>113</td>\n",
       "      <td>154</td>\n",
       "      <td>2812</td>\n",
       "      <td>1503</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>87991</td>\n",
       "      <td>2211</td>\n",
       "      <td>790</td>\n",
       "      <td>1119</td>\n",
       "      <td>61027</td>\n",
       "      <td>32048</td>\n",
       "      <td>1386</td>\n",
       "      <td>58</td>\n",
       "      <td>1572</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13594</td>\n",
       "      <td>671</td>\n",
       "      <td>410</td>\n",
       "      <td>580</td>\n",
       "      <td>6228</td>\n",
       "      <td>3200</td>\n",
       "      <td>396</td>\n",
       "      <td>19</td>\n",
       "      <td>325</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>85093</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9218</td>\n",
       "      <td>810</td>\n",
       "      <td>756</td>\n",
       "      <td>1003</td>\n",
       "      <td>5654</td>\n",
       "      <td>3230</td>\n",
       "      <td>422</td>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>85093</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7536</td>\n",
       "      <td>733</td>\n",
       "      <td>708</td>\n",
       "      <td>985</td>\n",
       "      <td>4750</td>\n",
       "      <td>2876</td>\n",
       "      <td>392</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>81370</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6229</td>\n",
       "      <td>537</td>\n",
       "      <td>508</td>\n",
       "      <td>687</td>\n",
       "      <td>3961</td>\n",
       "      <td>2104</td>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>81370</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7216</td>\n",
       "      <td>625</td>\n",
       "      <td>572</td>\n",
       "      <td>795</td>\n",
       "      <td>4742</td>\n",
       "      <td>2388</td>\n",
       "      <td>363</td>\n",
       "      <td>4</td>\n",
       "      <td>93</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>81370</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7564</td>\n",
       "      <td>626</td>\n",
       "      <td>574</td>\n",
       "      <td>832</td>\n",
       "      <td>4534</td>\n",
       "      <td>2452</td>\n",
       "      <td>370</td>\n",
       "      <td>7</td>\n",
       "      <td>91</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Page total likes  Type_Link  Type_Photo  Type_Status  Type_Video  \\\n",
       "0              139441          0           1            0           0   \n",
       "1              139441          0           0            1           0   \n",
       "2              139441          0           1            0           0   \n",
       "3              139441          0           1            0           0   \n",
       "4              139441          0           1            0           0   \n",
       "..                ...        ...         ...          ...         ...   \n",
       "494             85093          0           1            0           0   \n",
       "495             85093          0           1            0           0   \n",
       "496             81370          0           1            0           0   \n",
       "497             81370          0           1            0           0   \n",
       "498             81370          0           1            0           0   \n",
       "\n",
       "     Category  Post Month  Post Weekday  Post Hour  Paid  ...  \\\n",
       "0           2          12             4          3     0  ...   \n",
       "1           2          12             3         10     0  ...   \n",
       "2           3          12             3          3     0  ...   \n",
       "3           2          12             2         10     1  ...   \n",
       "4           2          12             2          3     0  ...   \n",
       "..        ...         ...           ...        ...   ...  ...   \n",
       "494         3           1             7         10     0  ...   \n",
       "495         3           1             7          2     0  ...   \n",
       "496         2           1             5          8     0  ...   \n",
       "497         1           1             5          2     0  ...   \n",
       "498         3           1             4         11     0  ...   \n",
       "\n",
       "     Lifetime Post Total Impressions  Lifetime Engaged Users  \\\n",
       "0                               5091                     178   \n",
       "1                              19057                    1457   \n",
       "2                               4373                     177   \n",
       "3                              87991                    2211   \n",
       "4                              13594                     671   \n",
       "..                               ...                     ...   \n",
       "494                             9218                     810   \n",
       "495                             7536                     733   \n",
       "496                             6229                     537   \n",
       "497                             7216                     625   \n",
       "498                             7564                     626   \n",
       "\n",
       "     Lifetime Post Consumers  Lifetime Post Consumptions  \\\n",
       "0                        109                         159   \n",
       "1                       1361                        1674   \n",
       "2                        113                         154   \n",
       "3                        790                        1119   \n",
       "4                        410                         580   \n",
       "..                       ...                         ...   \n",
       "494                      756                        1003   \n",
       "495                      708                         985   \n",
       "496                      508                         687   \n",
       "497                      572                         795   \n",
       "498                      574                         832   \n",
       "\n",
       "     Lifetime Post Impressions by people who have liked your Page  \\\n",
       "0                                                 3078              \n",
       "1                                                11710              \n",
       "2                                                 2812              \n",
       "3                                                61027              \n",
       "4                                                 6228              \n",
       "..                                                 ...              \n",
       "494                                               5654              \n",
       "495                                               4750              \n",
       "496                                               3961              \n",
       "497                                               4742              \n",
       "498                                               4534              \n",
       "\n",
       "     Lifetime Post reach by people who like your Page  \\\n",
       "0                                                1640   \n",
       "1                                                6112   \n",
       "2                                                1503   \n",
       "3                                               32048   \n",
       "4                                                3200   \n",
       "..                                                ...   \n",
       "494                                              3230   \n",
       "495                                              2876   \n",
       "496                                              2104   \n",
       "497                                              2388   \n",
       "498                                              2452   \n",
       "\n",
       "     Lifetime People who have liked your Page and engaged with your post  \\\n",
       "0                                                  119                     \n",
       "1                                                 1108                     \n",
       "2                                                  132                     \n",
       "3                                                 1386                     \n",
       "4                                                  396                     \n",
       "..                                                 ...                     \n",
       "494                                                422                     \n",
       "495                                                392                     \n",
       "496                                                301                     \n",
       "497                                                363                     \n",
       "498                                                370                     \n",
       "\n",
       "     comment  like  share  \n",
       "0          4    79     17  \n",
       "1          5   130     29  \n",
       "2          0    66     14  \n",
       "3         58  1572    147  \n",
       "4         19   325     49  \n",
       "..       ...   ...    ...  \n",
       "494       10   125     41  \n",
       "495        5    53     26  \n",
       "496        0    53     22  \n",
       "497        4    93     18  \n",
       "498        7    91     38  \n",
       "\n",
       "[495 rows x 21 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2=fb_df.drop(\"Total Interactions\",axis=1)\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       100\n",
       "1       164\n",
       "2        80\n",
       "3      1777\n",
       "4       393\n",
       "       ... \n",
       "494     176\n",
       "495      84\n",
       "496      75\n",
       "497     115\n",
       "498     136\n",
       "Name: Total Interactions, Length: 495, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2=fb_df[\"Total Interactions\"]\n",
    "Y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(X2,Y2, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create linear regression object\n",
    "l_reg_fb_df = linear_model.LinearRegression()\n",
    " \n",
    "# train the model using the training sets\n",
    "l_reg_fb_df.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, gamma=0.1, max_iter=10000)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf_fb_df  = SVR(kernel=\"rbf\", C=100,max_iter=10000, gamma=0.1, epsilon=0.1)\n",
    "svr_rbf_fb_df.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=100, random_state=0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_regr_fb_df  = DecisionTreeRegressor(max_depth=100, random_state=0)\n",
    "dr_regr_fb_df.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_f_fb_df= RandomForestRegressor(random_state=0)\n",
    "r_f_fb_df.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=8)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_fb_df = KNeighborsRegressor(n_neighbors=8)\n",
    "kn_fb_df.fit(x_train2,y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_fb_df  = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "ada_fb_df.fit(x_train2,y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=0.1, n_restarts_optimizer=10, normalize_y=True,\n",
       "                         random_state=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr_fb_df  = gp.GaussianProcessRegressor(n_restarts_optimizer=10, alpha=0.1, normalize_y=True, random_state=0)\n",
    "gpr_fb_df.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 128)               2816      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 167,681\n",
      "Trainable params: 167,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 442.0592 - mean_absolute_error: 442.0592 - val_loss: 265.8475 - val_mean_absolute_error: 265.8475\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 135.9589 - mean_absolute_error: 135.9589 - val_loss: 257.5655 - val_mean_absolute_error: 257.5655\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 121.3809 - mean_absolute_error: 121.3809 - val_loss: 222.2875 - val_mean_absolute_error: 222.2875\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 110.4722 - mean_absolute_error: 110.4722 - val_loss: 223.7496 - val_mean_absolute_error: 223.7496\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 109.4437 - mean_absolute_error: 109.4437 - val_loss: 217.3868 - val_mean_absolute_error: 217.3868\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 109.5406 - mean_absolute_error: 109.5406 - val_loss: 224.5226 - val_mean_absolute_error: 224.5226\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 107.5017 - mean_absolute_error: 107.5017 - val_loss: 202.3305 - val_mean_absolute_error: 202.3305\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 102.1809 - mean_absolute_error: 102.1809 - val_loss: 229.2663 - val_mean_absolute_error: 229.2663\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 107.8746 - mean_absolute_error: 107.8746 - val_loss: 199.3808 - val_mean_absolute_error: 199.3808\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 101.6769 - mean_absolute_error: 101.6769 - val_loss: 213.1403 - val_mean_absolute_error: 213.1403\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 100.8610 - mean_absolute_error: 100.8610 - val_loss: 212.6752 - val_mean_absolute_error: 212.6752\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 103.8218 - mean_absolute_error: 103.8218 - val_loss: 226.5636 - val_mean_absolute_error: 226.5636\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 97.5523 - mean_absolute_error: 97.5523 - val_loss: 223.4298 - val_mean_absolute_error: 223.4298\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 98.4266 - mean_absolute_error: 98.4266 - val_loss: 216.2102 - val_mean_absolute_error: 216.2102\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 100.1519 - mean_absolute_error: 100.1519 - val_loss: 182.5045 - val_mean_absolute_error: 182.5045\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 107.1422 - mean_absolute_error: 107.1422 - val_loss: 203.4808 - val_mean_absolute_error: 203.4808\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 102.3071 - mean_absolute_error: 102.3071 - val_loss: 244.6594 - val_mean_absolute_error: 244.6594\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 118.8331 - mean_absolute_error: 118.8331 - val_loss: 263.9197 - val_mean_absolute_error: 263.9197\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 109.4611 - mean_absolute_error: 109.4611 - val_loss: 192.3164 - val_mean_absolute_error: 192.3164\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 115.4398 - mean_absolute_error: 115.4398 - val_loss: 186.4326 - val_mean_absolute_error: 186.4326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f531a4cc9d0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model2 = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model2.add(Dense(128, kernel_initializer='normal',input_dim = x_train2.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model2.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model2.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model2.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model2.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model2.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model2.summary()\n",
    "NN_model2.fit(x_train2, y_train2, epochs=20, batch_size=32, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.0161754547981288e-24\n",
      "R2: 1.0\n"
     ]
    }
   ],
   "source": [
    "output = l_reg_fb_df.predict(x_test2)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test2, output)))\n",
    "print(f'R2: {r2_score(y_test2, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 91222.42060533223\n",
      "R2: -0.04955724319782595\n"
     ]
    }
   ],
   "source": [
    "output = svr_rbf_fb_df.predict(x_test2)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test2, output)))\n",
    "print(f'R2: {r2_score(y_test2, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3181.878787878788\n",
      "R2: 0.9633909744267355\n"
     ]
    }
   ],
   "source": [
    "output = dr_regr_fb_df.predict(x_test2)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test2, output)))\n",
    "print(f'R2: {r2_score(y_test2, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2644.500937373738\n",
      "R2: 0.9695737616361628\n"
     ]
    }
   ],
   "source": [
    "output = r_f_fb_df.predict(x_test2)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test2, output)))\n",
    "print(f'R2: {r2_score(y_test2, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 76387.68371212122\n",
      "R2: 0.12112344532024999\n"
     ]
    }
   ],
   "source": [
    "output = kn_fb_df.predict(x_test2)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test2, output)))\n",
    "print(f'R2: {r2_score(y_test2, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3344.254634661731\n",
      "R2: 0.9615227632459695\n"
     ]
    }
   ],
   "source": [
    "output = ada_fb_df.predict(x_test2)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test2, output)))\n",
    "print(f'R2: {r2_score(y_test2, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 87010.35588205286\n",
      "R2: -0.001095439511841656\n"
     ]
    }
   ],
   "source": [
    "output = gpr_fb_df.predict(x_test2)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test2, output)))\n",
    "print(f'R2: {r2_score(y_test2, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 57442.78404098236\n",
      "R2: 0.3390935072804083\n"
     ]
    }
   ],
   "source": [
    "output = NN_model2.predict(x_test2)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test2, output)))\n",
    "print(f'R2: {r2_score(y_test2, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 5: Bike Sharing (use hour data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "bike=pd.read_csv('datasets/hour.csv')\n",
    "bike=bike.drop(['instant','dteday'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>11</td>\n",
       "      <td>108</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>7</td>\n",
       "      <td>83</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17378</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17379 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       season  yr  mnth  hr  holiday  weekday  workingday  weathersit  temp  \\\n",
       "0           1   0     1   0        0        6           0           1  0.24   \n",
       "1           1   0     1   1        0        6           0           1  0.22   \n",
       "2           1   0     1   2        0        6           0           1  0.22   \n",
       "3           1   0     1   3        0        6           0           1  0.24   \n",
       "4           1   0     1   4        0        6           0           1  0.24   \n",
       "...       ...  ..   ...  ..      ...      ...         ...         ...   ...   \n",
       "17374       1   1    12  19        0        1           1           2  0.26   \n",
       "17375       1   1    12  20        0        1           1           2  0.26   \n",
       "17376       1   1    12  21        0        1           1           1  0.26   \n",
       "17377       1   1    12  22        0        1           1           1  0.26   \n",
       "17378       1   1    12  23        0        1           1           1  0.26   \n",
       "\n",
       "        atemp   hum  windspeed  casual  registered  cnt  \n",
       "0      0.2879  0.81     0.0000       3          13   16  \n",
       "1      0.2727  0.80     0.0000       8          32   40  \n",
       "2      0.2727  0.80     0.0000       5          27   32  \n",
       "3      0.2879  0.75     0.0000       3          10   13  \n",
       "4      0.2879  0.75     0.0000       0           1    1  \n",
       "...       ...   ...        ...     ...         ...  ...  \n",
       "17374  0.2576  0.60     0.1642      11         108  119  \n",
       "17375  0.2576  0.60     0.1642       8          81   89  \n",
       "17376  0.2576  0.60     0.1642       7          83   90  \n",
       "17377  0.2727  0.56     0.1343      13          48   61  \n",
       "17378  0.2727  0.65     0.1343      12          37   49  \n",
       "\n",
       "[17379 rows x 15 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>11</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>7</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17378</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17379 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       season  yr  mnth  hr  holiday  weekday  workingday  weathersit  temp  \\\n",
       "0           1   0     1   0        0        6           0           1  0.24   \n",
       "1           1   0     1   1        0        6           0           1  0.22   \n",
       "2           1   0     1   2        0        6           0           1  0.22   \n",
       "3           1   0     1   3        0        6           0           1  0.24   \n",
       "4           1   0     1   4        0        6           0           1  0.24   \n",
       "...       ...  ..   ...  ..      ...      ...         ...         ...   ...   \n",
       "17374       1   1    12  19        0        1           1           2  0.26   \n",
       "17375       1   1    12  20        0        1           1           2  0.26   \n",
       "17376       1   1    12  21        0        1           1           1  0.26   \n",
       "17377       1   1    12  22        0        1           1           1  0.26   \n",
       "17378       1   1    12  23        0        1           1           1  0.26   \n",
       "\n",
       "        atemp   hum  windspeed  casual  registered  \n",
       "0      0.2879  0.81     0.0000       3          13  \n",
       "1      0.2727  0.80     0.0000       8          32  \n",
       "2      0.2727  0.80     0.0000       5          27  \n",
       "3      0.2879  0.75     0.0000       3          10  \n",
       "4      0.2879  0.75     0.0000       0           1  \n",
       "...       ...   ...        ...     ...         ...  \n",
       "17374  0.2576  0.60     0.1642      11         108  \n",
       "17375  0.2576  0.60     0.1642       8          81  \n",
       "17376  0.2576  0.60     0.1642       7          83  \n",
       "17377  0.2727  0.56     0.1343      13          48  \n",
       "17378  0.2727  0.65     0.1343      12          37  \n",
       "\n",
       "[17379 rows x 14 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3=bike.drop('cnt',axis=1)\n",
    "X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         16\n",
       "1         40\n",
       "2         32\n",
       "3         13\n",
       "4          1\n",
       "        ... \n",
       "17374    119\n",
       "17375     89\n",
       "17376     90\n",
       "17377     61\n",
       "17378     49\n",
       "Name: cnt, Length: 17379, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y3=bike['cnt']\n",
    "Y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(X3,Y3, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create linear regression object\n",
    "l_reg_bike = linear_model.LinearRegression()\n",
    " \n",
    "# train the model using the training sets\n",
    "l_reg_bike.fit(x_train3, y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=100, gamma=0.1, max_iter=100)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf_bike  = SVR(kernel=\"rbf\", C=100,max_iter=100, gamma=0.1, epsilon=0.1)\n",
    "svr_rbf_bike.fit(x_train3, y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=100, random_state=0)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_regr_bike = DecisionTreeRegressor(max_depth=100, random_state=0)\n",
    "dr_regr_bike.fit(x_train3, y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_f_bike= RandomForestRegressor(random_state=0)\n",
    "r_f_bike.fit(x_train3, y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=8)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_bike = KNeighborsRegressor(n_neighbors=8)\n",
    "kn_bike.fit(x_train3,y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_bike  = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "ada_bike.fit(x_train3,y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=0.1, n_restarts_optimizer=10, normalize_y=True,\n",
       "                         random_state=0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr_bike = gp.GaussianProcessRegressor(n_restarts_optimizer=10, alpha=0.1, normalize_y=True, random_state=0)\n",
    "gpr_bike.fit(x_train3, y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 128)               1920      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166,785\n",
      "Trainable params: 166,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 10.3546 - mean_absolute_error: 10.3546 - val_loss: 6.1546 - val_mean_absolute_error: 6.1546\n",
      "Epoch 2/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 4.4372 - mean_absolute_error: 4.4372 - val_loss: 1.6081 - val_mean_absolute_error: 1.6081\n",
      "Epoch 3/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 4.5137 - mean_absolute_error: 4.5137 - val_loss: 4.1779 - val_mean_absolute_error: 4.1779\n",
      "Epoch 4/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 3.2773 - mean_absolute_error: 3.2773 - val_loss: 5.6752 - val_mean_absolute_error: 5.6752\n",
      "Epoch 5/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 3.4368 - mean_absolute_error: 3.4368 - val_loss: 0.8665 - val_mean_absolute_error: 0.8665\n",
      "Epoch 6/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 3.1157 - mean_absolute_error: 3.1157 - val_loss: 1.8911 - val_mean_absolute_error: 1.8911\n",
      "Epoch 7/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 2.9687 - mean_absolute_error: 2.9687 - val_loss: 8.1743 - val_mean_absolute_error: 8.1743\n",
      "Epoch 8/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 2.7301 - mean_absolute_error: 2.7301 - val_loss: 3.8520 - val_mean_absolute_error: 3.8520\n",
      "Epoch 9/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 3.3465 - mean_absolute_error: 3.3465 - val_loss: 0.7094 - val_mean_absolute_error: 0.7094\n",
      "Epoch 10/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 2.7111 - mean_absolute_error: 2.7111 - val_loss: 8.3039 - val_mean_absolute_error: 8.3039\n",
      "Epoch 11/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 2.6987 - mean_absolute_error: 2.6987 - val_loss: 2.4517 - val_mean_absolute_error: 2.4517\n",
      "Epoch 12/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 2.8066 - mean_absolute_error: 2.8066 - val_loss: 0.8168 - val_mean_absolute_error: 0.8168\n",
      "Epoch 13/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 3.3840 - mean_absolute_error: 3.3840 - val_loss: 4.0647 - val_mean_absolute_error: 4.0647\n",
      "Epoch 14/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 2.2505 - mean_absolute_error: 2.2505 - val_loss: 1.8939 - val_mean_absolute_error: 1.8939\n",
      "Epoch 15/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 2.5245 - mean_absolute_error: 2.5245 - val_loss: 3.0878 - val_mean_absolute_error: 3.0878\n",
      "Epoch 16/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 2.4918 - mean_absolute_error: 2.4918 - val_loss: 0.6710 - val_mean_absolute_error: 0.6710\n",
      "Epoch 17/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 3.0486 - mean_absolute_error: 3.0486 - val_loss: 1.7967 - val_mean_absolute_error: 1.7967\n",
      "Epoch 18/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 2.4150 - mean_absolute_error: 2.4150 - val_loss: 0.1889 - val_mean_absolute_error: 0.1889\n",
      "Epoch 19/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 2.5977 - mean_absolute_error: 2.5977 - val_loss: 0.9854 - val_mean_absolute_error: 0.9854\n",
      "Epoch 20/20\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 1.8305 - mean_absolute_error: 1.8305 - val_loss: 2.2779 - val_mean_absolute_error: 2.2779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f531a35eb50>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model3 = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model3.add(Dense(128, kernel_initializer='normal',input_dim = x_train3.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model3.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model3.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model3.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model3.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model3.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model3.summary()\n",
    "NN_model3.fit(x_train3, y_train3, epochs=20, batch_size=32, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3.483068131878882e-26\n",
      "R2: 1.0\n"
     ]
    }
   ],
   "source": [
    "output = l_reg_bike.predict(x_test3)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test3, output)))\n",
    "print(f'R2: {r2_score(y_test3, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 75495.86377526302\n",
      "R2: -1.4194543232162875\n"
     ]
    }
   ],
   "source": [
    "output = svr_rbf_bike.predict(x_test3)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test3, output)))\n",
    "print(f'R2: {r2_score(y_test3, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 22.65506329113924\n",
      "R2: 0.9992739616704611\n"
     ]
    }
   ],
   "source": [
    "output = dr_regr_bike.predict(x_test3)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test3, output)))\n",
    "print(f'R2: {r2_score(y_test3, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 4.3250337169159945\n",
      "R2: 0.9998613934459297\n"
     ]
    }
   ],
   "source": [
    "output = r_f_bike.predict(x_test3)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test3, output)))\n",
    "print(f'R2: {r2_score(y_test3, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 4.001708141542002\n",
      "R2: 0.9998717552249998\n"
     ]
    }
   ],
   "source": [
    "output = kn_bike.predict(x_test3)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test3, output)))\n",
    "print(f'R2: {r2_score(y_test3, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 902.9181399391056\n",
      "R2: 0.9710637233890174\n"
     ]
    }
   ],
   "source": [
    "output = ada_bike.predict(x_test3)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test3, output)))\n",
    "print(f'R2: {r2_score(y_test3, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 25489.04760670041\n",
      "R2: 0.18313953450117715\n"
     ]
    }
   ],
   "source": [
    "output = gpr_bike.predict(x_test3)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test3, output)))\n",
    "print(f'R2: {r2_score(y_test3, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 10.71079543144721\n",
      "R2: 0.99965674569419\n"
     ]
    }
   ],
   "source": [
    "output = NN_model3.predict(x_test3)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test3, output.flatten())))\n",
    "print(f'R2: {r2_score(y_test3, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 6: Student Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_GP</th>\n",
       "      <th>school_MS</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>age</th>\n",
       "      <th>address_R</th>\n",
       "      <th>address_U</th>\n",
       "      <th>famsize_GT3</th>\n",
       "      <th>famsize_LE3</th>\n",
       "      <th>Pstatus_A</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     school_GP  school_MS  sex_F  sex_M  age  address_R  address_U  \\\n",
       "0            1          0      1      0   18          0          1   \n",
       "1            1          0      1      0   17          0          1   \n",
       "2            1          0      1      0   15          0          1   \n",
       "3            1          0      1      0   15          0          1   \n",
       "4            1          0      1      0   16          0          1   \n",
       "..         ...        ...    ...    ...  ...        ...        ...   \n",
       "644          0          1      1      0   19          1          0   \n",
       "645          0          1      1      0   18          0          1   \n",
       "646          0          1      1      0   18          0          1   \n",
       "647          0          1      0      1   17          0          1   \n",
       "648          0          1      0      1   18          1          0   \n",
       "\n",
       "     famsize_GT3  famsize_LE3  Pstatus_A  ...  famrel  freetime  goout  Dalc  \\\n",
       "0              1            0          1  ...       4         3      4     1   \n",
       "1              1            0          0  ...       5         3      3     1   \n",
       "2              0            1          0  ...       4         3      2     2   \n",
       "3              1            0          0  ...       3         2      2     1   \n",
       "4              1            0          0  ...       4         3      2     1   \n",
       "..           ...          ...        ...  ...     ...       ...    ...   ...   \n",
       "644            1            0          0  ...       5         4      2     1   \n",
       "645            0            1          0  ...       4         3      4     1   \n",
       "646            1            0          0  ...       1         1      1     1   \n",
       "647            0            1          0  ...       2         4      5     3   \n",
       "648            0            1          0  ...       4         4      1     3   \n",
       "\n",
       "     Walc  health  absences  G1  G2  G3  \n",
       "0       1       3         4   0  11  11  \n",
       "1       1       3         2   9  11  11  \n",
       "2       3       3         6  12  13  12  \n",
       "3       1       5         0  14  14  14  \n",
       "4       2       5         0  11  13  13  \n",
       "..    ...     ...       ...  ..  ..  ..  \n",
       "644     2       5         4  10  11  10  \n",
       "645     1       1         4  15  15  16  \n",
       "646     1       5         6  11  12   9  \n",
       "647     4       2         6  10  10  10  \n",
       "648     4       5         4  10  11  11  \n",
       "\n",
       "[649 rows x 59 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing data\n",
    "stu=pd.read_csv('datasets/student-por.csv', sep=';')\n",
    "features_cat = ['school',\"sex\",'address','famsize','Pstatus','Mjob','Fjob','reason','guardian','schoolsup','famsup','paid','activities','nursery','higher','internet','romantic']\n",
    "\n",
    "# replace the columns with categorical values by its one hot encoding\n",
    "for feat in features_cat:\n",
    "    tmp_df = pd.get_dummies(stu[feat], prefix=feat)\n",
    "    idx = stu.columns.get_loc(feat)\n",
    "    for i, col in enumerate(tmp_df.columns):\n",
    "        stu.insert(idx+i, col, tmp_df[col])\n",
    "    stu = stu.drop(feat, axis=1)\n",
    "\n",
    "stu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_GP</th>\n",
       "      <th>school_MS</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>age</th>\n",
       "      <th>address_R</th>\n",
       "      <th>address_U</th>\n",
       "      <th>famsize_GT3</th>\n",
       "      <th>famsize_LE3</th>\n",
       "      <th>Pstatus_A</th>\n",
       "      <th>...</th>\n",
       "      <th>romantic_yes</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     school_GP  school_MS  sex_F  sex_M  age  address_R  address_U  \\\n",
       "0            1          0      1      0   18          0          1   \n",
       "1            1          0      1      0   17          0          1   \n",
       "2            1          0      1      0   15          0          1   \n",
       "3            1          0      1      0   15          0          1   \n",
       "4            1          0      1      0   16          0          1   \n",
       "..         ...        ...    ...    ...  ...        ...        ...   \n",
       "644          0          1      1      0   19          1          0   \n",
       "645          0          1      1      0   18          0          1   \n",
       "646          0          1      1      0   18          0          1   \n",
       "647          0          1      0      1   17          0          1   \n",
       "648          0          1      0      1   18          1          0   \n",
       "\n",
       "     famsize_GT3  famsize_LE3  Pstatus_A  ...  romantic_yes  famrel  freetime  \\\n",
       "0              1            0          1  ...             0       4         3   \n",
       "1              1            0          0  ...             0       5         3   \n",
       "2              0            1          0  ...             0       4         3   \n",
       "3              1            0          0  ...             1       3         2   \n",
       "4              1            0          0  ...             0       4         3   \n",
       "..           ...          ...        ...  ...           ...     ...       ...   \n",
       "644            1            0          0  ...             0       5         4   \n",
       "645            0            1          0  ...             0       4         3   \n",
       "646            1            0          0  ...             0       1         1   \n",
       "647            0            1          0  ...             0       2         4   \n",
       "648            0            1          0  ...             0       4         4   \n",
       "\n",
       "     goout  Dalc  Walc  health  absences  G1  G3  \n",
       "0        4     1     1       3         4   0  11  \n",
       "1        3     1     1       3         2   9  11  \n",
       "2        2     2     3       3         6  12  12  \n",
       "3        2     1     1       5         0  14  14  \n",
       "4        2     1     2       5         0  11  13  \n",
       "..     ...   ...   ...     ...       ...  ..  ..  \n",
       "644      2     1     2       5         4  10  10  \n",
       "645      4     1     1       1         4  15  16  \n",
       "646      1     1     1       5         6  11   9  \n",
       "647      5     3     4       2         6  10  10  \n",
       "648      1     3     4       5         4  10  11  \n",
       "\n",
       "[649 rows x 58 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X4=stu.drop(\"G2\",axis=1)\n",
    "X4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      11\n",
       "1      11\n",
       "2      13\n",
       "3      14\n",
       "4      13\n",
       "       ..\n",
       "644    11\n",
       "645    15\n",
       "646    12\n",
       "647    10\n",
       "648    11\n",
       "Name: G2, Length: 649, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y4=stu[\"G2\"]\n",
    "Y4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "x_train4, x_test4, y_train4, y_test4 = train_test_split(X4,Y4, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create linear regression object\n",
    "l_reg_stu = linear_model.LinearRegression()\n",
    " \n",
    "# train the model using the training sets\n",
    "l_reg_stu.fit(x_train4, y_train4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, gamma=0.1, max_iter=10000)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf_stu  = SVR(kernel=\"rbf\", C=100,max_iter=10000, gamma=0.1, epsilon=0.1)\n",
    "svr_rbf_stu.fit(x_train4, y_train4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=100, random_state=0)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_regr_stu = DecisionTreeRegressor(max_depth=100, random_state=0)\n",
    "dr_regr_stu.fit(x_train4, y_train4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_f_stu= RandomForestRegressor(random_state=0)\n",
    "r_f_stu.fit(x_train4, y_train4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=8)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_stu = KNeighborsRegressor(n_neighbors=8)\n",
    "# n_neighbors=8\n",
    "\n",
    "kn_stu.fit(x_train4,y_train4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_stu  = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "ada_stu.fit(x_train4,y_train4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=0.1, n_restarts_optimizer=10, normalize_y=True,\n",
       "                         random_state=0)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr_stu  = gp.GaussianProcessRegressor(n_restarts_optimizer=10, alpha=0.1, normalize_y=True, random_state=0)\n",
    "gpr_stu.fit(x_train4, y_train4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 128)               7552      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 172,417\n",
      "Trainable params: 172,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.2582 - mean_absolute_error: 7.2582 - val_loss: 2.7810 - val_mean_absolute_error: 2.7810\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.2784 - mean_absolute_error: 2.2784 - val_loss: 1.8085 - val_mean_absolute_error: 1.8085\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.4892 - mean_absolute_error: 1.4892 - val_loss: 1.0888 - val_mean_absolute_error: 1.0888\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0490 - mean_absolute_error: 1.0490 - val_loss: 1.0038 - val_mean_absolute_error: 1.0038\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.8372 - mean_absolute_error: 0.8372 - val_loss: 0.8569 - val_mean_absolute_error: 0.8569\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7885 - mean_absolute_error: 0.7885 - val_loss: 0.7838 - val_mean_absolute_error: 0.7838\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7369 - mean_absolute_error: 0.7369 - val_loss: 0.7516 - val_mean_absolute_error: 0.7516\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7165 - mean_absolute_error: 0.7165 - val_loss: 0.7489 - val_mean_absolute_error: 0.7489\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7488 - mean_absolute_error: 0.7488 - val_loss: 0.7327 - val_mean_absolute_error: 0.7327\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7035 - mean_absolute_error: 0.7035 - val_loss: 0.7524 - val_mean_absolute_error: 0.7524\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6989 - mean_absolute_error: 0.6989 - val_loss: 0.7184 - val_mean_absolute_error: 0.7184\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6896 - mean_absolute_error: 0.6896 - val_loss: 0.7327 - val_mean_absolute_error: 0.7327\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6835 - mean_absolute_error: 0.6835 - val_loss: 0.8291 - val_mean_absolute_error: 0.8291\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.8344 - mean_absolute_error: 0.8344 - val_loss: 1.0905 - val_mean_absolute_error: 1.0905\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.8814 - mean_absolute_error: 0.8814 - val_loss: 0.9782 - val_mean_absolute_error: 0.9782\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7787 - mean_absolute_error: 0.7787 - val_loss: 0.7178 - val_mean_absolute_error: 0.7178\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7059 - mean_absolute_error: 0.7059 - val_loss: 0.7804 - val_mean_absolute_error: 0.7804\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7083 - mean_absolute_error: 0.7083 - val_loss: 0.7312 - val_mean_absolute_error: 0.7312\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6899 - mean_absolute_error: 0.6899 - val_loss: 0.7610 - val_mean_absolute_error: 0.7610\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6895 - mean_absolute_error: 0.6895 - val_loss: 0.9389 - val_mean_absolute_error: 0.9389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f531a1dd970>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model4 = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model4.add(Dense(128, kernel_initializer='normal',input_dim = x_train4.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model4.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model4.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model4.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model4.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model4.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model4.summary()\n",
    "NN_model4.fit(x_train4, y_train4, epochs=20, batch_size=32, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.7089040096581276\n",
      "R2: 0.8095407570549055\n"
     ]
    }
   ],
   "source": [
    "# l_reg_stu.score(x_train4, y_train4)\n",
    "output = l_reg_stu.predict(x_test4)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test4, output)))\n",
    "print(f'R2: {r2_score(y_test4, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 4.031380801176884\n",
      "R2: 0.5506981485934122\n"
     ]
    }
   ],
   "source": [
    "# svr_rbf_stu.score(x_train4, y_train4)\n",
    "output = svr_rbf_stu.predict(x_test4)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test4, output)))\n",
    "print(f'R2: {r2_score(y_test4, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.076923076923077\n",
      "R2: 0.768524624759292\n"
     ]
    }
   ],
   "source": [
    "# dr_regr_stu.score(x_train4, y_train4)\n",
    "output = dr_regr_stu.predict(x_test4)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test4, output)))\n",
    "print(f'R2: {r2_score(y_test4, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.5914315384615385\n",
      "R2: 0.822633193964494\n"
     ]
    }
   ],
   "source": [
    "# r_f_stu.score(x_train4, y_train4)\n",
    "output = r_f_stu.predict(x_test4)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test4, output)))\n",
    "print(f'R2: {r2_score(y_test4, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.5837740384615384\n",
      "R2: 0.8234866308132633\n"
     ]
    }
   ],
   "source": [
    "# kn_stu.score(x_train4, y_train4)\n",
    "output = kn_stu.predict(x_test4)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test4, output)))\n",
    "print(f'R2: {r2_score(y_test4, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.84546170494011\n",
      "R2: 0.794321250801341\n"
     ]
    }
   ],
   "source": [
    "# ada_stu.score(x_train4, y_train4)\n",
    "output = ada_stu.predict(x_test4)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test4, output)))\n",
    "print(f'R2: {r2_score(y_test4, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 8.961006253974288\n",
      "R2: 0.0012859367685412737\n"
     ]
    }
   ],
   "source": [
    "# gpr_stu.score(x_train4, y_train4)\n",
    "output = gpr_stu.predict(x_test4)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test4, output)))\n",
    "print(f'R2: {r2_score(y_test4, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.073651538299123\n",
      "R2: 0.7688892413592077\n"
     ]
    }
   ],
   "source": [
    "# predictions = NN_model4.predict(x_test4)\n",
    "# predictions\n",
    "output = NN_model4.predict(x_test4)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test4, output.flatten())))\n",
    "print(f'R2: {r2_score(y_test4, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 7: Concrete Compressive Strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "con=pd.read_excel('datasets/Concrete_Data.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement (component 1)(kg in a m^3 mixture)</th>\n",
       "      <th>Blast Furnace Slag (component 2)(kg in a m^3 mixture)</th>\n",
       "      <th>Fly Ash (component 3)(kg in a m^3 mixture)</th>\n",
       "      <th>Water  (component 4)(kg in a m^3 mixture)</th>\n",
       "      <th>Superplasticizer (component 5)(kg in a m^3 mixture)</th>\n",
       "      <th>Coarse Aggregate  (component 6)(kg in a m^3 mixture)</th>\n",
       "      <th>Fine Aggregate (component 7)(kg in a m^3 mixture)</th>\n",
       "      <th>Age (day)</th>\n",
       "      <th>Concrete compressive strength(MPa, megapascals)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.986111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.887366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.269535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.052780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.296075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.284354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "      <td>31.178794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "      <td>23.696601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "      <td>32.768036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "      <td>32.401235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cement (component 1)(kg in a m^3 mixture)  \\\n",
       "0                                         540.0   \n",
       "1                                         540.0   \n",
       "2                                         332.5   \n",
       "3                                         332.5   \n",
       "4                                         198.6   \n",
       "...                                         ...   \n",
       "1025                                      276.4   \n",
       "1026                                      322.2   \n",
       "1027                                      148.5   \n",
       "1028                                      159.1   \n",
       "1029                                      260.9   \n",
       "\n",
       "      Blast Furnace Slag (component 2)(kg in a m^3 mixture)  \\\n",
       "0                                                   0.0       \n",
       "1                                                   0.0       \n",
       "2                                                 142.5       \n",
       "3                                                 142.5       \n",
       "4                                                 132.4       \n",
       "...                                                 ...       \n",
       "1025                                              116.0       \n",
       "1026                                                0.0       \n",
       "1027                                              139.4       \n",
       "1028                                              186.7       \n",
       "1029                                              100.5       \n",
       "\n",
       "      Fly Ash (component 3)(kg in a m^3 mixture)  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "...                                          ...   \n",
       "1025                                        90.3   \n",
       "1026                                       115.6   \n",
       "1027                                       108.6   \n",
       "1028                                         0.0   \n",
       "1029                                        78.3   \n",
       "\n",
       "      Water  (component 4)(kg in a m^3 mixture)  \\\n",
       "0                                         162.0   \n",
       "1                                         162.0   \n",
       "2                                         228.0   \n",
       "3                                         228.0   \n",
       "4                                         192.0   \n",
       "...                                         ...   \n",
       "1025                                      179.6   \n",
       "1026                                      196.0   \n",
       "1027                                      192.7   \n",
       "1028                                      175.6   \n",
       "1029                                      200.6   \n",
       "\n",
       "      Superplasticizer (component 5)(kg in a m^3 mixture)  \\\n",
       "0                                                   2.5     \n",
       "1                                                   2.5     \n",
       "2                                                   0.0     \n",
       "3                                                   0.0     \n",
       "4                                                   0.0     \n",
       "...                                                 ...     \n",
       "1025                                                8.9     \n",
       "1026                                               10.4     \n",
       "1027                                                6.1     \n",
       "1028                                               11.3     \n",
       "1029                                                8.6     \n",
       "\n",
       "      Coarse Aggregate  (component 6)(kg in a m^3 mixture)  \\\n",
       "0                                                1040.0      \n",
       "1                                                1055.0      \n",
       "2                                                 932.0      \n",
       "3                                                 932.0      \n",
       "4                                                 978.4      \n",
       "...                                                 ...      \n",
       "1025                                              870.1      \n",
       "1026                                              817.9      \n",
       "1027                                              892.4      \n",
       "1028                                              989.6      \n",
       "1029                                              864.5      \n",
       "\n",
       "      Fine Aggregate (component 7)(kg in a m^3 mixture)  Age (day)  \\\n",
       "0                                                 676.0         28   \n",
       "1                                                 676.0         28   \n",
       "2                                                 594.0        270   \n",
       "3                                                 594.0        365   \n",
       "4                                                 825.5        360   \n",
       "...                                                 ...        ...   \n",
       "1025                                              768.3         28   \n",
       "1026                                              813.4         28   \n",
       "1027                                              780.0         28   \n",
       "1028                                              788.9         28   \n",
       "1029                                              761.5         28   \n",
       "\n",
       "      Concrete compressive strength(MPa, megapascals)   \n",
       "0                                            79.986111  \n",
       "1                                            61.887366  \n",
       "2                                            40.269535  \n",
       "3                                            41.052780  \n",
       "4                                            44.296075  \n",
       "...                                                ...  \n",
       "1025                                         44.284354  \n",
       "1026                                         31.178794  \n",
       "1027                                         23.696601  \n",
       "1028                                         32.768036  \n",
       "1029                                         32.401235  \n",
       "\n",
       "[1030 rows x 9 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement (component 1)(kg in a m^3 mixture)</th>\n",
       "      <th>Blast Furnace Slag (component 2)(kg in a m^3 mixture)</th>\n",
       "      <th>Fly Ash (component 3)(kg in a m^3 mixture)</th>\n",
       "      <th>Water  (component 4)(kg in a m^3 mixture)</th>\n",
       "      <th>Superplasticizer (component 5)(kg in a m^3 mixture)</th>\n",
       "      <th>Coarse Aggregate  (component 6)(kg in a m^3 mixture)</th>\n",
       "      <th>Fine Aggregate (component 7)(kg in a m^3 mixture)</th>\n",
       "      <th>Age (day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cement (component 1)(kg in a m^3 mixture)  \\\n",
       "0                                         540.0   \n",
       "1                                         540.0   \n",
       "2                                         332.5   \n",
       "3                                         332.5   \n",
       "4                                         198.6   \n",
       "...                                         ...   \n",
       "1025                                      276.4   \n",
       "1026                                      322.2   \n",
       "1027                                      148.5   \n",
       "1028                                      159.1   \n",
       "1029                                      260.9   \n",
       "\n",
       "      Blast Furnace Slag (component 2)(kg in a m^3 mixture)  \\\n",
       "0                                                   0.0       \n",
       "1                                                   0.0       \n",
       "2                                                 142.5       \n",
       "3                                                 142.5       \n",
       "4                                                 132.4       \n",
       "...                                                 ...       \n",
       "1025                                              116.0       \n",
       "1026                                                0.0       \n",
       "1027                                              139.4       \n",
       "1028                                              186.7       \n",
       "1029                                              100.5       \n",
       "\n",
       "      Fly Ash (component 3)(kg in a m^3 mixture)  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "...                                          ...   \n",
       "1025                                        90.3   \n",
       "1026                                       115.6   \n",
       "1027                                       108.6   \n",
       "1028                                         0.0   \n",
       "1029                                        78.3   \n",
       "\n",
       "      Water  (component 4)(kg in a m^3 mixture)  \\\n",
       "0                                         162.0   \n",
       "1                                         162.0   \n",
       "2                                         228.0   \n",
       "3                                         228.0   \n",
       "4                                         192.0   \n",
       "...                                         ...   \n",
       "1025                                      179.6   \n",
       "1026                                      196.0   \n",
       "1027                                      192.7   \n",
       "1028                                      175.6   \n",
       "1029                                      200.6   \n",
       "\n",
       "      Superplasticizer (component 5)(kg in a m^3 mixture)  \\\n",
       "0                                                   2.5     \n",
       "1                                                   2.5     \n",
       "2                                                   0.0     \n",
       "3                                                   0.0     \n",
       "4                                                   0.0     \n",
       "...                                                 ...     \n",
       "1025                                                8.9     \n",
       "1026                                               10.4     \n",
       "1027                                                6.1     \n",
       "1028                                               11.3     \n",
       "1029                                                8.6     \n",
       "\n",
       "      Coarse Aggregate  (component 6)(kg in a m^3 mixture)  \\\n",
       "0                                                1040.0      \n",
       "1                                                1055.0      \n",
       "2                                                 932.0      \n",
       "3                                                 932.0      \n",
       "4                                                 978.4      \n",
       "...                                                 ...      \n",
       "1025                                              870.1      \n",
       "1026                                              817.9      \n",
       "1027                                              892.4      \n",
       "1028                                              989.6      \n",
       "1029                                              864.5      \n",
       "\n",
       "      Fine Aggregate (component 7)(kg in a m^3 mixture)  Age (day)  \n",
       "0                                                 676.0         28  \n",
       "1                                                 676.0         28  \n",
       "2                                                 594.0        270  \n",
       "3                                                 594.0        365  \n",
       "4                                                 825.5        360  \n",
       "...                                                 ...        ...  \n",
       "1025                                              768.3         28  \n",
       "1026                                              813.4         28  \n",
       "1027                                              780.0         28  \n",
       "1028                                              788.9         28  \n",
       "1029                                              761.5         28  \n",
       "\n",
       "[1030 rows x 8 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X5=con.drop(['Concrete compressive strength(MPa, megapascals) '],axis=1)\n",
    "X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       79.986111\n",
       "1       61.887366\n",
       "2       40.269535\n",
       "3       41.052780\n",
       "4       44.296075\n",
       "          ...    \n",
       "1025    44.284354\n",
       "1026    31.178794\n",
       "1027    23.696601\n",
       "1028    32.768036\n",
       "1029    32.401235\n",
       "Name: Concrete compressive strength(MPa, megapascals) , Length: 1030, dtype: float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y5=con['Concrete compressive strength(MPa, megapascals) ']\n",
    "Y5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "x_train5, x_test5, y_train5, y_test5 = train_test_split(X5,Y5, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create linear regression object\n",
    "l_reg_con = linear_model.LinearRegression()\n",
    " \n",
    "# train the model using the training sets\n",
    "l_reg_con.fit(x_train5, y_train5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, gamma=0.1, max_iter=10000)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf_con  = SVR(kernel=\"rbf\", C=100,max_iter=10000, gamma=0.1, epsilon=0.1)\n",
    "svr_rbf_con.fit(x_train5, y_train5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=100, random_state=0)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_regr_con = DecisionTreeRegressor(max_depth=100, random_state=0)\n",
    "dr_regr_con.fit(x_train5, y_train5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_f_con= RandomForestRegressor(random_state=0)\n",
    "r_f_con.fit(x_train5, y_train5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=8)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_con = KNeighborsRegressor(n_neighbors=8)\n",
    "# n_neighbors=8\n",
    "\n",
    "kn_con.fit(x_train5,y_train5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_con  = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "ada_con.fit(x_train5,y_train5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=0.1, n_restarts_optimizer=10, normalize_y=True,\n",
       "                         random_state=0)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr_con  = gp.GaussianProcessRegressor(n_restarts_optimizer=10, alpha=0.1, normalize_y=True, random_state=0)\n",
    "gpr_con.fit(x_train5, y_train5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 128)               1152      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166,017\n",
      "Trainable params: 166,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 16.1052 - mean_absolute_error: 16.1052 - val_loss: 11.5762 - val_mean_absolute_error: 11.5762\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.9642 - mean_absolute_error: 10.9642 - val_loss: 9.7025 - val_mean_absolute_error: 9.7025\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.0205 - mean_absolute_error: 10.0205 - val_loss: 8.7820 - val_mean_absolute_error: 8.7820\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.4184 - mean_absolute_error: 8.4184 - val_loss: 7.2323 - val_mean_absolute_error: 7.2323\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2741 - mean_absolute_error: 8.2741 - val_loss: 7.2174 - val_mean_absolute_error: 7.2174\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6580 - mean_absolute_error: 7.6580 - val_loss: 6.5800 - val_mean_absolute_error: 6.5800\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.3286 - mean_absolute_error: 7.3286 - val_loss: 8.7661 - val_mean_absolute_error: 8.7661\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 7.3514 - mean_absolute_error: 7.3514 - val_loss: 6.2465 - val_mean_absolute_error: 6.2465\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.1717 - mean_absolute_error: 7.1717 - val_loss: 6.2505 - val_mean_absolute_error: 6.2505\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.6923 - mean_absolute_error: 6.6923 - val_loss: 5.6193 - val_mean_absolute_error: 5.6193\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.4430 - mean_absolute_error: 6.4430 - val_loss: 5.6664 - val_mean_absolute_error: 5.6664\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.4454 - mean_absolute_error: 6.4454 - val_loss: 5.6455 - val_mean_absolute_error: 5.6455\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.3178 - mean_absolute_error: 6.3178 - val_loss: 5.2799 - val_mean_absolute_error: 5.2799\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 6.7949 - mean_absolute_error: 6.7949 - val_loss: 5.2605 - val_mean_absolute_error: 5.2605\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.5094 - mean_absolute_error: 6.5094 - val_loss: 5.9139 - val_mean_absolute_error: 5.9139\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.0100 - mean_absolute_error: 7.0100 - val_loss: 6.4380 - val_mean_absolute_error: 6.4380\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.7528 - mean_absolute_error: 5.7528 - val_loss: 5.3269 - val_mean_absolute_error: 5.3269\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.6600 - mean_absolute_error: 5.6600 - val_loss: 5.6800 - val_mean_absolute_error: 5.6800\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 6.4272 - mean_absolute_error: 6.4272 - val_loss: 5.8888 - val_mean_absolute_error: 5.8888\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.1396 - mean_absolute_error: 6.1396 - val_loss: 5.8715 - val_mean_absolute_error: 5.8715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5319f35ca0>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model5 = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model5.add(Dense(128, kernel_initializer='normal',input_dim = x_train5.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model5.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model5.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model5.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model5.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model5.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model5.summary()\n",
    "NN_model5.fit(x_train5, y_train5, epochs=20, batch_size=32, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 102.53727023099904\n",
      "R2: 0.5535428894989083\n"
     ]
    }
   ],
   "source": [
    "output = l_reg_con.predict(x_test5)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test5, output)))\n",
    "print(f'R2: {r2_score(y_test5, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 168.55781987573704\n",
      "R2: 0.2660830833066753\n"
     ]
    }
   ],
   "source": [
    "output = svr_rbf_con.predict(x_test5)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test5, output)))\n",
    "print(f'R2: {r2_score(y_test5, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 36.944090350238916\n",
      "R2: 0.8391418867432217\n"
     ]
    }
   ],
   "source": [
    "output = dr_regr_con.predict(x_test5)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test5, output)))\n",
    "print(f'R2: {r2_score(y_test5, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 16.585909627708478\n",
      "R2: 0.9277833584730997\n"
     ]
    }
   ],
   "source": [
    "output = r_f_con.predict(x_test5)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test5, output)))\n",
    "print(f'R2: {r2_score(y_test5, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 83.10034604045161\n",
      "R2: 0.6381731219167508\n"
     ]
    }
   ],
   "source": [
    "output = kn_con.predict(x_test5)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test5, output)))\n",
    "print(f'R2: {r2_score(y_test5, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 52.3542938552905\n",
      "R2: 0.7720443824542965\n"
     ]
    }
   ],
   "source": [
    "output = ada_con.predict(x_test5)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test5, output)))\n",
    "print(f'R2: {r2_score(y_test5, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 193.33371686286029\n",
      "R2: 0.1582064511901351\n"
     ]
    }
   ],
   "source": [
    "output = gpr_con.predict(x_test5)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test5, output)))\n",
    "print(f'R2: {r2_score(y_test5, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 54.06825118336087\n",
      "R2: 0.7645816478360589\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = NN_model5.predict(x_test5)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test5, output.flatten())))\n",
    "print(f'R2: {r2_score(y_test5, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 8: SGEMM GPU kernel performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "sge=pd.read_csv('datasets/sgemm_product.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "sge=sge.iloc[-10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MWG</th>\n",
       "      <th>NWG</th>\n",
       "      <th>KWG</th>\n",
       "      <th>MDIMC</th>\n",
       "      <th>NDIMC</th>\n",
       "      <th>MDIMA</th>\n",
       "      <th>NDIMB</th>\n",
       "      <th>KWI</th>\n",
       "      <th>VWM</th>\n",
       "      <th>VWN</th>\n",
       "      <th>STRM</th>\n",
       "      <th>STRN</th>\n",
       "      <th>SA</th>\n",
       "      <th>SB</th>\n",
       "      <th>Run1 (ms)</th>\n",
       "      <th>Run2 (ms)</th>\n",
       "      <th>Run3 (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231600</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>276.01</td>\n",
       "      <td>278.68</td>\n",
       "      <td>278.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231601</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>200.92</td>\n",
       "      <td>202.71</td>\n",
       "      <td>203.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231602</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>179.35</td>\n",
       "      <td>176.94</td>\n",
       "      <td>176.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231603</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>189.54</td>\n",
       "      <td>189.66</td>\n",
       "      <td>189.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231604</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>289.42</td>\n",
       "      <td>291.90</td>\n",
       "      <td>291.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241595</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.96</td>\n",
       "      <td>17.77</td>\n",
       "      <td>17.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241596</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.04</td>\n",
       "      <td>36.03</td>\n",
       "      <td>36.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241597</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.28</td>\n",
       "      <td>34.82</td>\n",
       "      <td>35.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241598</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28.43</td>\n",
       "      <td>28.49</td>\n",
       "      <td>28.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241599</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.94</td>\n",
       "      <td>17.79</td>\n",
       "      <td>17.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MWG  NWG  KWG  MDIMC  NDIMC  MDIMA  NDIMB  KWI  VWM  VWN  STRM  STRN  \\\n",
       "231600  128  128   32     16     16      8      8    2    1    2     0     0   \n",
       "231601  128  128   32     16     16      8      8    2    1    2     0     0   \n",
       "231602  128  128   32     16     16      8      8    2    1    2     0     0   \n",
       "231603  128  128   32     16     16      8      8    2    1    2     0     0   \n",
       "231604  128  128   32     16     16      8      8    2    1    2     0     1   \n",
       "...     ...  ...  ...    ...    ...    ...    ...  ...  ...  ...   ...   ...   \n",
       "241595  128  128   32     32     32     32     32    8    4    4     1     0   \n",
       "241596  128  128   32     32     32     32     32    8    4    4     1     1   \n",
       "241597  128  128   32     32     32     32     32    8    4    4     1     1   \n",
       "241598  128  128   32     32     32     32     32    8    4    4     1     1   \n",
       "241599  128  128   32     32     32     32     32    8    4    4     1     1   \n",
       "\n",
       "        SA  SB  Run1 (ms)  Run2 (ms)  Run3 (ms)  \n",
       "231600   0   0     276.01     278.68     278.95  \n",
       "231601   0   1     200.92     202.71     203.07  \n",
       "231602   1   0     179.35     176.94     176.29  \n",
       "231603   1   1     189.54     189.66     189.64  \n",
       "231604   0   0     289.42     291.90     291.96  \n",
       "...     ..  ..        ...        ...        ...  \n",
       "241595   1   1      17.96      17.77      17.77  \n",
       "241596   0   0      36.04      36.03      36.04  \n",
       "241597   0   1      35.28      34.82      35.27  \n",
       "241598   1   0      28.43      28.49      28.44  \n",
       "241599   1   1      17.94      17.79      17.77  \n",
       "\n",
       "[10000 rows x 17 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X6=sge.drop('Run4 (ms)',axis=1)\n",
    "X6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231600    279.37\n",
       "231601    204.25\n",
       "231602    175.75\n",
       "231603    189.67\n",
       "231604    292.51\n",
       "           ...  \n",
       "241595     17.77\n",
       "241596     36.03\n",
       "241597     35.27\n",
       "241598     28.45\n",
       "241599     17.77\n",
       "Name: Run4 (ms), Length: 10000, dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y6=sge['Run4 (ms)']\n",
    "Y6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "x_train6, x_test6, y_train6, y_test6 = train_test_split(X6,Y6, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create linear regression object\n",
    "l_reg_sge = linear_model.LinearRegression()\n",
    " \n",
    "# train the model using the training sets\n",
    "l_reg_sge.fit(x_train6, y_train6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=100, gamma=0.1, max_iter=100)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf_sge  = SVR(kernel=\"rbf\", C=100,max_iter=100, gamma=0.1, epsilon=0.1)\n",
    "svr_rbf_sge.fit(x_train6, y_train6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=100, random_state=0)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_regr_sge = DecisionTreeRegressor(max_depth=100, random_state=0)\n",
    "dr_regr_sge.fit(x_train6, y_train6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_f_sge= RandomForestRegressor(random_state=0)\n",
    "r_f_sge.fit(x_train6, y_train6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=8)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_sge = KNeighborsRegressor(n_neighbors=8)\n",
    "# n_neighbors=8\n",
    "\n",
    "kn_sge.fit(x_train6,y_train6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_sge  = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "ada_sge.fit(x_train6,y_train6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=0.1, n_restarts_optimizer=10, normalize_y=True,\n",
       "                         random_state=0)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr_sge  = gp.GaussianProcessRegressor(n_restarts_optimizer=10, alpha=0.1, normalize_y=True, random_state=0)\n",
    "gpr_sge.fit(x_train6, y_train6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_35 (Dense)            (None, 128)               2304      \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 167,169\n",
      "Trainable params: 167,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 12.3618 - mean_absolute_error: 12.3618 - val_loss: 2.5285 - val_mean_absolute_error: 2.5285\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.7477 - mean_absolute_error: 2.7477 - val_loss: 1.3485 - val_mean_absolute_error: 1.3485\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.6644 - mean_absolute_error: 4.6644 - val_loss: 1.5393 - val_mean_absolute_error: 1.5393\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.1996 - mean_absolute_error: 2.1996 - val_loss: 0.9927 - val_mean_absolute_error: 0.9927\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 3.0323 - mean_absolute_error: 3.0323 - val_loss: 2.4738 - val_mean_absolute_error: 2.4738\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.9878 - mean_absolute_error: 2.9878 - val_loss: 2.4820 - val_mean_absolute_error: 2.4820\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.7748 - mean_absolute_error: 2.7748 - val_loss: 1.5560 - val_mean_absolute_error: 1.5560\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 3.3320 - mean_absolute_error: 3.3320 - val_loss: 0.7237 - val_mean_absolute_error: 0.7237\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.9790 - mean_absolute_error: 1.9790 - val_loss: 0.9809 - val_mean_absolute_error: 0.9809\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 3.1193 - mean_absolute_error: 3.1193 - val_loss: 3.7272 - val_mean_absolute_error: 3.7272\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.9350 - mean_absolute_error: 2.9350 - val_loss: 4.3228 - val_mean_absolute_error: 4.3228\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.9275 - mean_absolute_error: 2.9275 - val_loss: 1.3285 - val_mean_absolute_error: 1.3285\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.9764 - mean_absolute_error: 1.9764 - val_loss: 2.0865 - val_mean_absolute_error: 2.0865\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.6885 - mean_absolute_error: 1.6885 - val_loss: 1.9883 - val_mean_absolute_error: 1.9883\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.7738 - mean_absolute_error: 1.7738 - val_loss: 1.7134 - val_mean_absolute_error: 1.7134\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.4924 - mean_absolute_error: 1.4924 - val_loss: 3.0799 - val_mean_absolute_error: 3.0799\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.2096 - mean_absolute_error: 2.2096 - val_loss: 0.9784 - val_mean_absolute_error: 0.9784\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.5165 - mean_absolute_error: 1.5165 - val_loss: 0.7549 - val_mean_absolute_error: 0.7549\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.7820 - mean_absolute_error: 1.7820 - val_loss: 0.7474 - val_mean_absolute_error: 0.7474\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 2.2043 - mean_absolute_error: 2.2043 - val_loss: 4.2077 - val_mean_absolute_error: 4.2077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f531a7cadf0>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model6 = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model6.add(Dense(128, kernel_initializer='normal',input_dim = x_train6.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model6.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model6.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model6.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model6.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model6.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model6.summary()\n",
    "NN_model6.fit(x_train6, y_train6, epochs=20, batch_size=32, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.3524163193272245\n",
      "R2: 0.9999593336076236\n"
     ]
    }
   ],
   "source": [
    "output = l_reg_sge.predict(x_test6)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test6, output)))\n",
    "print(f'R2: {r2_score(y_test6, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 7302.432841610674\n",
      "R2: 0.15735003473540055\n"
     ]
    }
   ],
   "source": [
    "output = svr_rbf_sge.predict(x_test6)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test6, output)))\n",
    "print(f'R2: {r2_score(y_test6, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.7265603500000006\n",
      "R2: 0.9999161599884628\n"
     ]
    }
   ],
   "source": [
    "output = dr_regr_sge.predict(x_test6)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test6, output)))\n",
    "print(f'R2: {r2_score(y_test6, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.4181442268049996\n",
      "R2: 0.9999517490642044\n"
     ]
    }
   ],
   "source": [
    "output = r_f_sge.predict(x_test6)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test6, output)))\n",
    "print(f'R2: {r2_score(y_test6, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.3300306968750009\n",
      "R2: 0.9998465237072587\n"
     ]
    }
   ],
   "source": [
    "output = kn_sge.predict(x_test6)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test6, output)))\n",
    "print(f'R2: {r2_score(y_test6, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 33.76193473220228\n",
      "R2: 0.9961041075287614\n"
     ]
    }
   ],
   "source": [
    "output = ada_sge.predict(x_test6)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test6, output)))\n",
    "print(f'R2: {r2_score(y_test6, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 4647.231272482056\n",
      "R2: 0.4637418302542269\n"
     ]
    }
   ],
   "source": [
    "output = gpr_sge.predict(x_test6)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test6, output)))\n",
    "print(f'R2: {r2_score(y_test6, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 23.08005935866221\n",
      "R2: 0.9973367216599295\n"
     ]
    }
   ],
   "source": [
    "output = NN_model6.predict(x_test6)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test6, output.flatten())))\n",
    "print(f'R2: {r2_score(y_test6, output)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
